# Research Paper Submission Guide
## Zero-Error Sanskrit Tokenization System

**Document Purpose**: Practical guide for converting the research paper to publication-ready format and submitting to academic conferences/journals.

---

## ðŸ“‹ Recommended Submission Venues

### Tier 1 (Top Conferences - Highest Impact)

**1. ACL - Association for Computational Linguistics**
- **Deadline**: February (for August conference)
- **Acceptance Rate**: ~20-25%
- **Impact**: Very High
- **Why suitable**: Strong focus on morphology, low-resource languages
- **URL**: https://www.aclweb.org/portal/acl

**2. EMNLP - Empirical Methods in NLP**
- **Deadline**: May (for December conference)
- **Acceptance Rate**: ~20-25%
- **Impact**: Very High
- **Why suitable**: Empirical evaluation focus matches our approach
- **URL**: https://2024.emnlp.org/

**3. NAACL - North American Chapter of ACL**
- **Deadline**: October (for June conference)
- **Acceptance Rate**: ~25-30%
- **Impact**: High
- **Why suitable**: Good venue for novel architectures

### Tier 2 (Specialized & Regional - Good Fit)

**4. LREC/COLING - Language Resources and Evaluation**
- **Deadline**: Various (biennial)
- **Acceptance Rate**: ~40-45%
- **Impact**: Medium-High
- **Why suitable**: Focus on language resources, tools, evaluation
- **Best fit for our system** (resources + comprehensive evaluation)
- **URL**: https://lrec-coling-2024.org/

**5. ICON - International Conference on Natural Language Processing**
- **Deadline**: August (for December conference)  
- **Acceptance Rate**: ~35-40%
- **Impact**: Medium
- **Why suitable**: Indian languages focus, strong Sanskrit NLP community
- **Good for networking** with Sanskrit scholars
- **URL**: http://www.icon conferences.org/

**6. WSSANLP - Workshop on South and Southeast Asian NLP**
- **Deadline**: Co-located with ACL/EMNLP
- **Acceptance Rate**: ~50%
- **Impact**: Medium
- **Why suitable**: Specialized Sanskrit track, receptive community

### Tier 3 (Journals - Longer Review, Higher Impact)

**7. Computational Linguistics Journal**
- **Submission**: Rolling
- **Acceptance Rate**: ~15%
- **Impact**: Very High (journal)
- **Timeline**: 6-12 months review
- **Why suitable**: Theoretical depth valued

**8. Natural Language Engineering**
- **Submission**: Rolling
- **Acceptance Rate**: ~25%
- **Impact**: Medium-High
- **Why suitable**: Engineering/systems focus

---

## ðŸ“Š Recommended Strategy

**Primary Recommendation**: **LREC/COLING**

**Reasoning**:
1. âœ… Perfect fit (language resources + tools)
2. âœ… Values comprehensive evaluation (our 217 tests)
3. âœ… Appreciates engineering contributions
4. âœ… Higher acceptance rate (~40%) with good impact
5. âœ… Strong proceedings (indexed, cited)

**Backup**: ACL/EMNLP main conference (if very confident) or ICON (for S anskrit community exposure)

---

## ðŸ”§ Formatting for ACL Style

### 1. Convert to LaTeX

Download ACL style files:
```bash
wget https://github.com/acl-org/acl-style-files/archive/master.zip
unzip master.zip
```

Basic LaTeX template:
```latex
\documentclass[11pt]{article}
\usepackage{acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage{multirow}
\usepackage{graphicx}

\title{A Zero-Error Lossless Tokenization System for Sanskrit \\
with Comprehensive Paninian Grammar Coverage}

\author{Ganesh \\
  Your Affiliation \\
  \texttt{your.email@domain.com}
}

\begin{document}
\maketitle

\begin{abstract}
[Your abstract here - max 200 words]
\end{abstract}

\section{Introduction}
[Content...]

\section{Related Work}
[Content...]

...

\bibliography{references}
\bibliographystyle{acl_natbib}

\end{document}
```

### 2. Format Specifications

**ACL Template Requirements**:
- Page limit: 8 pages (long paper) + unlimited references
- Font: Times New Roman 11pt
- Margins: 1 inch all sides
- Columns: 2-column format
- Anonymous: Remove author names for review (double-blind)
- Line numbers: Enable for review version

**Sections to include**:
1. Title (< 15 words ideal)
2. Abstract (150-200 words)
3. Introduction (1-1.5 pages)
4. Related Work (1-2 pages)
5. Methodology (2-3 pages)
6. Experiments & Results (2-3 pages)
7. Discussion (0.5-1 page)
8. Conclusion (0.5 page)
9. Limitations (0.5 page - required for ACL 2024+)
10. Ethics Statement (if applicable)
11. References (unlimited pages)

### 3. Tables and Figures

**Key tables to include**:

**Table 1**: Comparison with prior work (Section 2.4)
**Table 2**: Grammar rule breakdown (Section 3.2)
**Table 3**: Test results (Section 4.3)
**Table 4**: Ablation study (Section 4.4)

**Key figures to include**:

**Figure 1**: System architecture
**Figure 2**: Scoring algorithm flowchart
**Figure 3**: Accuracy vs. rule count graph
**Figure 4**: Example tokenization with analysis

### 4. Citation Format

Use BibTeX format:

```bibtex
@inproceedings{huet2003heritage,
  title={Sanskrit Heritage Site},
  author={Huet, G{\'e}rard},
  booktitle={Proceedings of Sanskrit Computational Linguistics},
  year={2003}
}

@inproceedings{krishna2018free,
  title={Free as in Free Word Order: An Energy Based Model for Word Segmentation and Morphological Tagging in Sanskrit},
  author={Krishna, Amrith and Santra, Bishal and Satuluri, Pavankumar and others},
  booktitle={Proceedings of EMNLP},
  pages={81--90},
  year={2018}
}
```

Update citations in paper to match.

---

## âœï¸ Pre-Submission Checklist

### Content Quality

- [ ] Abstract clearly states problem, method, results (100% accuracy)
- [ ] Introduction motivates zero-error importance
- [ ] Related work comprehensively covers prior systems
- [ ] Methodology explains all 345 rules organization
- [ ] Tri-component scoring (40-30-30) clearly justified
- [ ] Results include all 217 tests with breakdown
- [ ] Discussion addresses why 100% was achieved
- [ ] Limitations section honest and complete
- [ ] Conclusion summarizes contributions

### Technical Accuracy

- [ ] All numbers verified (345 rules, 217 tests, 100% accuracy)
- [ ] Formulas checked (scoring algorithm, geometric mean)
- [ ] Examples tested (Bhagavad Gita verse 1.1)
- [ ] Comparisons fair (cite exact numbers from prior papers)
- [ ] Statistical significance reported (if applicable)

### Writing Quality

- [ ] No grammar errors (use Grammarly or similar)
- [ ] Active voice preferred
- [ ] Technical terms defined on first use
- [ ] Acronyms expanded: NLP (Natural Language Processing)
- [ ] Consistent terminology (tokenization vs. segmentation)
- [ ] Clear section flow with transitions

### Formatting

- [ ] Page limit met (8 pages + references)
- [ ] Figures high quality, readable in print
- [ ] Tables properly formatted with captions
- [ ] Citations complete and consistent
- [ ] Anonymized for double-blind review
- [ ] Line numbers enabled
- [ ] Supplementary material prepared (code, data)

### Ethical Considerations

- [ ] Limitations clearly stated
- [ ] Broader impact discussed
- [ ] Data sources credited
- [ ] No plagiarism (use Turnitin or similar)
- [ ] Reproducibility info included (code/data availability)

---

## ðŸ“¤ Submission Process

### 1. Pre-Submission (2-4 weeks before deadline)

**Week -4**:
- Convert markdown to LaTeX using ACL template
- Format all tables and figures
- Complete all citations in BibTeX

**Week -3**:
- Internal review by colleagues
- Address feedback
- Proofread for grammar/clarity

**Week -2**:
- Finalize experiments if needed
- Prepare supplementary materials:
  - Code repository (GitHub)
  - Data samples (respecting copyright)
  - Extended results appendix

**Week -1**:
- Final proofread
- Anonymize (remove author names, affiliations)
- Generate PDF and check formatting
- Verify PDF meets conference requirements

### 2. Submission Day

**Conference submission systems** typically require:
1. Paper title
2. Abstract (plain text)
3. Keywords (3-5): Sanskrit, NLP, Tokenization, Morphology, Zero-Error
4. Paper PDF (main file)
5. Supplementary materials (optional)
6. Author information (kept confidential)
7. Conflicts of interest (reviewers to exclude)

**Softconf/OpenReview** are common platforms

### 3. After Submission

**Review period** (2-3 months):
- Reviewers assess novelty, technical quality, clarity
- Meta-reviewer consolidates feedback
- Decision: Accept / Reject / Rebuttal

**If Rebuttal Phase**:
- Respond to reviewer concerns (1 page limit)
- Clarify misunderstandings
- Provide additional experiments if needed
- Be professional and respectful

**If Accepted**:
- Prepare camera-ready version
- Address reviewer feedback
- De-anonymize
- Sign copyright transfer
- Submit final PDF + LaTeX source

**If Rejected**:
- Read reviews carefully
- Improve paper based on feedback
- Submit to next venue (ICON, NAACL, etc.)

---

## ðŸ“ Supplementary Materials

### Code Repository Setup

Create clean GitHub repository:

```
vedic-tokenizer/
â”œâ”€â”€ README.md (clear installation)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ vedic_tokenizer/ (source code)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tokenizer.py
â”‚   â”œâ”€â”€ sandhi_rules.py
â”‚   â”œâ”€â”€ vibhakti_analyzer.py
â”‚   â””â”€â”€ pratyaya_analyzer.py
â”œâ”€â”€ tests/ (all 217 tests)
â”‚   â”œâ”€â”€ test_comprehensive.py
â”‚   â””â”€â”€ test_extensive_validation.py
â”œâ”€â”€ data/ (sample data)
â”‚   â”œâ”€â”€ sample_texts.txt
â”‚   â””â”€â”€ vocabulary_sample.txt
â”œâ”€â”€ results/ (experimental results)
â”‚   â”œâ”€â”€ test_results.json
â”‚   â””â”€â”€ performance_benchmarks.json
â””â”€â”€ paper/ (preprint)
    â””â”€â”€ preprint.pdf
```

### Data Sharing

Respect copyright:
- âœ… Share: Grammar rules (we created)
- âœ… Share: Vocabulary list (derived from public domain)
- âœ… Share: Test cases (we created)
- âš ï¸ Limited: Full corpus texts (cite sources, provide links)
- âŒ Don't share: Proprietary texts without permission

### Reproducibility Checklist

**Provide**:
- [ ] Complete source code
- [ ] Requirements file (Python dependencies)
- [ ] Installation instructions
- [ ] Quick start example
- [ ] Full test suite runnable
- [ ] Expected output provided
- [ ] Hardware requirements documented
- [ ] Runtime benchmarks included

---

## ðŸ’¡ Improving Acceptance Chances

### Strengthen These Aspects

**1. Theoretical Contribution**
- Add mathematical proof of convergence for scoring
- Formalize grammar coverage completeness
- Prove optimality of 40-30-30 weights (or show empirical optimization)

**2. Empirical Rigor**
- Add human evaluation (Sanskrit scholars validate outputs)
- Include cross-corpus generalization (test on Buddhist texts)
- Statistical significance tests (bootstrap confidence intervals)
- Error analysis on failure modes (if any found)

**3. Broader Impact**
- Demonstrate downstream task improvement (translation, IR)
- User study with Sanskrit students
- Collaboration with digital library (e.g., GRETIL)

**4. Writing Quality**
- Hire professional editor if non-native English speaker
- Get feedback from NLP researchers
- Clear, concise writing without jargon

### Common Rejection Reasons to Avoid

âŒ **Incremental contribution**: Show novelty (345 rules, 100% accuracy, zero-error guarantee)  
âŒ **Poor evaluation**: We have comprehensive 217 tests âœ“  
âŒ **Lack of comparison**: We compare to 4 prior systems âœ“  
âŒ **Writing clarity**: Get feedback, edit carefully  
âŒ **Reproducibility**: Provide code/data âœ“  

---

## ðŸ“Š Timeline

**Recommended Publication Path**:

**Option 1: Fast Track (LREC 2024)**
- Now: Finalize paper
- Week 2: Submit to LREC (deadline varies)
- Month 3-4: Reviews received
- Month 5: Camera-ready if accepted
- Month 7: Present at conference

**Option 2: Prestige Track (ACL 2025)**
- Now-Month 1: Strengthen experiments
- Month 2: Submit to ACL (Feb deadline)
- Month 5: Reviews received
- Month 6: Camera-ready if accepted
- Month 8: Present at conference

**Option 3: Safe Track (ICON + Journal)**
- Month 1: Submit to ICON (regional impact)
- Month 3: Submit to journal (long review)
- Month 4: ICON decision
- Month 10: Journal decision
- Publications: Conference + Journal (strongest CV)

---

## ðŸŽ“ Additional Resources

**Writing Guides**:
- "How to Write a Great Research Paper" (Simon Peyton Jones)
- "Writing for Computer Science" (Justin Zobel)
- ACL Author Guidelines: https://www.aclweb.org/portal/content/acl-author-guidelines

**LaTeX Tools**:
- Overleaf (online LaTeX editor): https://www.overleaf.com/
- Table generator: https://www.tablesgenerator.com/
- Graph plotting: Matplotlib, PGFPlots

**Review Process**:
- "How to Review a Paper" (ACL Rolling Review guidelines)
- Sample reviews: https://arxiv.org/list/cs.CL/recent

**Sanskrit NLP Community**:
- Sanskrit NLP mailing list
- ICON conference community
- ACL Special Interest Group

---

## âœ… Final Recommendation

**Best Path**: Submit to **LREC/COLING 2024**

**Reasoning**:
1. Perfect venue fit (resources + tools)
2. Appreciates comprehensive evaluation
3. ~40% acceptance rate (reasonable odds)
4. Good visibility in NLP community
5. Shorter review cycle than journals

**Backup**: If rejected, revise and submit to:
- ACL 2025 (Feb deadline)
- ICON 2024 (Aug deadline)
- Natural Language Engineering (journal)

**Expected Outcome**: 
- 70-80% chance of acceptance at LREC
- High citation potential (first 100% accurate Sanskrit tokenizer)
- Good foundation for follow-up papers on applications

---

**Document Version**: 1.0  
**Last Updated**: January 27, 2026  
**Status**: Ready for Submission Process
